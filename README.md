# ollama_llm
- Use this model llame ` ollama run llama3.2:1b`



## Run program.
1. `python3 -m venv venv`
2. `source venv/bin/activate`
3. `pip install -r requirements.txt`
4. `python WS09_002_pdf.py`

## Now working well in:
- WS09_0001.py
- WS09_0002_pdf.py
- WS09_0002_txt_fixed.py
- WS09_0002_web_fixed.py


### Working in path
`/Users/atthana/Desktop/Private_Q/Trainings/17_voice_assistant_21-22Dec24/llama_workshop/llm_code`
